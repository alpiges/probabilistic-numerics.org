@article{2014arXiv14022058H,
  author =	 {P. {Hennig}},
  journal =	 {SIAM J on Optimization},
  month =	 Jan,
  title =	 {{Probabilistic Interpretation of Linear Solvers}},
  year =	 2015,
  link =	 {http://epubs.siam.org/doi/abs/10.1137/140955501?journalCode=sjope8},
  volume =	 25,
  issue =	 1,
  abstract =	 {This paper proposes a probabilistic framework for algorithms
that iteratively solve unconstrained linear problems Bx = b with positive
definite B for x. The goal is to replace the point estimates returned by
existing methods with a Gaussian posterior belief over the elements of the
inverse of B, which can be used to estimate errors. Recent probabilistic
interpretations of the secant family of quasi-Newton optimization algorithms
are extended. Combined with properties of the conjugate gradient algorithm,
this leads to uncertainty-calibrated methods with very limited cost overhead
over conjugate gradients, a self-contained novel interpretation of the
quasi-Newton and conjugate gradient algorithms, and a foundation for new
nonlinear optimization methods.},
  file =	 {http://probabilistic-numerics.org/assets/pdf/HennigLinear2015.pdf}
}

@inproceedings{fitzsimons_bayesian_2017,
  title = {Bayesian {Inference} of {Log} {Determinants}},
  url = {https://arxiv.org/abs/1704.01445},
  abstract = {The log-determinant of a kernel matrix appears in a variety of machine learning problems, ranging from determinantal point processes and generalized Markov random fields, through to the training of Gaussian processes. Exact calculation of this term is often intractable when the size of the kernel matrix exceeds a few thousand. In the spirit of probabilistic numerics, we reinterpret the problem of computing the log-determinant as a Bayesian inference problem. In particular, we combine prior knowledge in the form of bounds from matrix theory and evidence derived from stochastic trace estimation to obtain probabilistic estimates for the log-determinant and its associated uncertainty within a given computational budget. Beyond its novelty and theoretic appeal, the performance of our proposal is competitive with state-of-the-art approaches to approximating the log-determinant, while also quantifying the uncertainty due to budget-constrained evidence.},
  urldate = {2017-06-21},
  booktitle = {Uncertainty in {Artificial} {Intelligence}},
  author = {Fitzsimons, Jack and Cutajar, Kurt and Osborne, Michael and Roberts, Stephen and Filippone, Maurizio},
  year = {2017},
  file = {http://probabilistic-numerics.org/assets/pdf/Fitzsimons et al. - 2017 - Bayesian Inference of Log Determinants.pdf}
}
